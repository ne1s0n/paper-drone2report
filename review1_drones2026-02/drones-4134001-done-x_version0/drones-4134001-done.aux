\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\citation{machwitz2021bridging}
\citation{moyroud2018introduction}
\citation{tang2024grabseeds}
\citation{loarca2024berryportraits}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{intro}{{1}{2}{Introduction}{section.1}{}}
\newlabel{intro@cref}{{[section][1][]1}{[1][2][]2}}
\citation{noauthor_welcome_nodate}
\citation{rupnik2017micmac}
\citation{moyroud2018introduction}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}{section.2}\protected@file@percent }
\newlabel{methods}{{2}{3}{Methods}{section.2}{}}
\newlabel{methods@cref}{{[section][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data Workflow}{3}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces General application workflow. Panel a: drones capture raw, partial images of the field (depending on the mounted sensors). All images from a single flight are collated in a unique orthophoto. Panel b: orthophotos coming from one or more sensors, together with a shape file that specifies the ROIs, enter \textsc  {drone2report} and are converted to an internal \textit  {dataset} object. Panel c: all datasets are inputed, in turn, to all queued tasks, each task producing its specific output (e.g. tables, other images etc.)\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:workflow}{{1}{3}{General application workflow. Panel a: drones capture raw, partial images of the field (depending on the mounted sensors). All images from a single flight are collated in a unique orthophoto. Panel b: orthophotos coming from one or more sensors, together with a shape file that specifies the ROIs, enter \textsc {drone2report} and are converted to an internal \textit {dataset} object. Panel c: all datasets are inputed, in turn, to all queued tasks, each task producing its specific output (e.g. tables, other images etc.)\relax }{figure.caption.1}{}}
\newlabel{fig:workflow@cref}{{[figure][1][]1}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Software Implementation}{4}{subsection.2.2}\protected@file@percent }
\citation{GDALmanual}
\citation{kelsey_jordahl_2020_3946761}
\newlabel{lst:GLI_function}{{1}{5}{Example of function computing the GLI vegetation index on a passed image}{lstlisting.1}{}}
\newlabel{lst:GLI_function@cref}{{[listing][1][]1}{[1][5][]5}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces Example of function computing the GLI vegetation index on a passed image}}{5}{lstlisting.1}\protected@file@percent }
\citation{louhaichi2001spatially}
\citation{hamuda2016survey}
\citation{tang2024grabseeds}
\newlabel{lst:config}{{2}{6}{Example of configuration .ini file to run drone2report}{lstlisting.2}{}}
\newlabel{lst:config@cref}{{[listing][2][]2}{[1][5][]6}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces Example of configuration .ini file to run drone2report}}{6}{lstlisting.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{6}{section.3}\protected@file@percent }
\newlabel{results}{{3}{6}{Results}{section.3}{}}
\newlabel{results@cref}{{[section][3][]3}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Case Study N. 1: Thresholding}{6}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example RGB image of tobacco leaves (\textit  {Nicotiana tabacum}). A) The original image of the tobacco leaves as downloaded from \url  {https://www.dropbox.com/s/is4jrmlmmcfdpdp/test-data.zip?dl=1}; B) The same image with threshold 0.1: the pixels highlighted in turquoise are those that will be used for the calculations of the vegetation indices.\relax }}{7}{figure.caption.2}\protected@file@percent }
\newlabel{fig:tobacco-leaves}{{2}{7}{Example RGB image of tobacco leaves (\textit {Nicotiana tabacum}). A) The original image of the tobacco leaves as downloaded from \url {https://www.dropbox.com/s/is4jrmlmmcfdpdp/test-data.zip?dl=1}; B) The same image with threshold 0.1: the pixels highlighted in turquoise are those that will be used for the calculations of the vegetation indices.\relax }{figure.caption.2}{}}
\newlabel{fig:tobacco-leaves@cref}{{[figure][2][]2}{[1][7][]7}}
\newlabel{formula:GLI_index}{{1}{7}{Case Study N. 1: Thresholding}{equation.3.1}{}}
\newlabel{formula:GLI_index@cref}{{[equation][1][]1}{[1][7][]7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Distribution of values for the vegetation index GLI (Green Leaf Index) for: A) the tobacco leaves image; and B) for the barley field plot image\relax }}{8}{figure.caption.3}\protected@file@percent }
\newlabel{fig:gli}{{3}{8}{Distribution of values for the vegetation index GLI (Green Leaf Index) for: A) the tobacco leaves image; and B) for the barley field plot image\relax }{figure.caption.3}{}}
\newlabel{fig:gli@cref}{{[figure][3][]3}{[1][7][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example RGB image of one single barley field plot. A) The original image of the barley field: all pixels would be used for index calculations; B) The same plot with increasing thresholds for the index values: 0.2, 0.4, 0.6 (rescaled in $[0,1]$). As the threshold is increased, fewer and fewer pixels are used for the calculations of the index (indicated in turquoise).\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:base-field-plot}{{4}{8}{Example RGB image of one single barley field plot. A) The original image of the barley field: all pixels would be used for index calculations; B) The same plot with increasing thresholds for the index values: 0.2, 0.4, 0.6 (rescaled in $[0,1]$). As the threshold is increased, fewer and fewer pixels are used for the calculations of the index (indicated in turquoise).\relax }{figure.caption.4}{}}
\newlabel{fig:base-field-plot@cref}{{[figure][4][]4}{[1][8][]8}}
\citation{mathieu1998relationships}
\citation{meyer2008verification}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Green leaf index (GLI) values with different thresholding, as computed by [TASK index]. For each Region Of Interest (as defined in the shapefile) a set of summary statistics is computed for each index (mean, standard deviation, min and max). after\_th: n. of pixels left for the calculation after thresholding.\relax }}{9}{table.caption.5}\protected@file@percent }
\newlabel{tab:index-thresholds}{{1}{9}{Green leaf index (GLI) values with different thresholding, as computed by [TASK index]. For each Region Of Interest (as defined in the shapefile) a set of summary statistics is computed for each index (mean, standard deviation, min and max). after\_th: n. of pixels left for the calculation after thresholding.\relax }{table.caption.5}{}}
\newlabel{tab:index-thresholds@cref}{{[table][1][]1}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Case Study N. 2: Monitoring Vegetation Indices over Time}{9}{subsection.3.2}\protected@file@percent }
\newlabel{formula:HUE}{{2}{9}{Case Study N. 2: Monitoring Vegetation Indices over Time}{equation.3.2}{}}
\newlabel{formula:HUE@cref}{{[equation][2][]2}{[1][9][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Vegetation indices over time. A) The same barley plot drone-photographed in February, April, and June. B) Evolution of GLI index (left) and HUE index (right) values for twenty barley varieties over the entire growing season (10 flights in February-June 2024). Two arbitrary selected varieties are highlighted (red and blue).\relax }}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:time-curves}{{5}{10}{Vegetation indices over time. A) The same barley plot drone-photographed in February, April, and June. B) Evolution of GLI index (left) and HUE index (right) values for twenty barley varieties over the entire growing season (10 flights in February-June 2024). Two arbitrary selected varieties are highlighted (red and blue).\relax }{figure.caption.6}{}}
\newlabel{fig:time-curves@cref}{{[figure][5][]5}{[1][9][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Case Study N. 3: Detecting Lodging from DEM Files}{10}{subsection.3.3}\protected@file@percent }
\citation{henrich2012entwicklung}
\citation{2020SciPy-NMeth}
\citation{nelder1965simplex}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Example .dem file of a barley field (left: flight on 19/04/2024); plant height (metres) calculated from the .dem file by drone2report, over 10 flights covering the growing season (right).\relax }}{11}{figure.caption.7}\protected@file@percent }
\newlabel{fig:dem-height}{{6}{11}{Example .dem file of a barley field (left: flight on 19/04/2024); plant height (metres) calculated from the .dem file by drone2report, over 10 flights covering the growing season (right).\relax }{figure.caption.7}{}}
\newlabel{fig:dem-height@cref}{{[figure][6][]6}{[1][10][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Case Study N. 4: Index Optimization on Images Merged from Heterogeneous Sensors}{11}{subsection.3.4}\protected@file@percent }
\newlabel{optimal_index}{{3}{11}{Case Study N. 4: Index Optimization on Images Merged from Heterogeneous Sensors}{equation.3.3}{}}
\newlabel{optimal_index@cref}{{[equation][3][]3}{[1][11][]11}}
\citation{Peccia_2018}
\citation{he2016deep}
\citation{chollet2015keras}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Optimization trajectories through training cycles. The custom index described in Formula\nobreakspace  {}\ref {optimal_index} was optimized for maximal Pearson's correlation between the vector of its per-plot averages and the phenotype \textit  {heading date}. Solid lines show three optimization trajectories on different input images, namely RGB, 10-bands multispectral, and a 14-bands merged image containing RGB, multispectral and temperature data. For reference, the two best performing indices (NDVI and GLI) are also reported.  \relax }}{12}{figure.caption.8}\protected@file@percent }
\newlabel{fig:optimization_trajectory}{{7}{12}{Optimization trajectories through training cycles. The custom index described in Formula~\ref {optimal_index} was optimized for maximal Pearson's correlation between the vector of its per-plot averages and the phenotype \textit {heading date}. Solid lines show three optimization trajectories on different input images, namely RGB, 10-bands multispectral, and a 14-bands merged image containing RGB, multispectral and temperature data. For reference, the two best performing indices (NDVI and GLI) are also reported.  \relax }{figure.caption.8}{}}
\newlabel{fig:optimization_trajectory@cref}{{[figure][7][]7}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Case Study N. 5: Deep Learning for Image Classification}{12}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Optimization trajectories through training cycles. The top panel reports the value of the loss function (computed as categorical crossentropy) for the train and validation sets through the training epochs. The bottom panel reports the accuracy, computed as the fraction of correct predictions over the total number of samples.  \relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{fig:classification_resnet}{{8}{13}{Optimization trajectories through training cycles. The top panel reports the value of the loss function (computed as categorical crossentropy) for the train and validation sets through the training epochs. The bottom panel reports the accuracy, computed as the fraction of correct predictions over the total number of samples.  \relax }{figure.caption.9}{}}
\newlabel{fig:classification_resnet@cref}{{[figure][8][]8}{[1][13][]13}}
\citation{tanaka_review_2024,gano2024drone}
\citation{gano_dronebased_2024}
\citation{sharma2021development}
\citation{vacca2020web}
\citation{noauthor_orfeo_nodate,grizonnet_orfeo_2017}
\citation{moyroud2018introduction}
\citation{dobesova2020evaluation}
\citation{noauthor_plantcv_2021}
\citation{tang2024grabseeds}
\citation{loarca2024berryportraits}
\citation{varghese2024yolov8}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{14}{section.4}\protected@file@percent }
\newlabel{discussion}{{4}{14}{Discussion}{section.4}{}}
\newlabel{discussion@cref}{{[section][4][]4}{[1][14][]14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}State of the Art and Positioning of \textsc  {drone2report}}{14}{subsection.4.1}\protected@file@percent }
\citation{matias_fieldimager_2020}
\citation{ChenZhang2020}
\citation{itoh2024preps}
\citation{wang2024ihup}
\citation{candiago2015evaluating,radovcaj2023state,velez2023beyond}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Applications, Limitations and Future Developments}{16}{subsection.4.2}\protected@file@percent }
\bibcite{machwitz2021bridging}{{1}{2021}{{Machwitz et~al.}}{{}}}
\bibcite{moyroud2018introduction}{{2}{2018}{{Moyroud and Portet}}{{}}}
\bibcite{tang2024grabseeds}{{3}{2024}{{Tang et~al.}}{{}}}
\bibcite{loarca2024berryportraits}{{4}{2024}{{Loarca et~al.}}{{}}}
\bibcite{noauthor_welcome_nodate}{{5}{}{{}}{{}}}
\bibcite{rupnik2017micmac}{{6}{2017}{{Rupnik et~al.}}{{}}}
\bibcite{GDALmanual}{{7}{2025}{{{GDAL/OGR contributors}}}{{}}}
\bibcite{kelsey_jordahl_2020_3946761}{{8}{2020}{{Jordahl et~al.}}{{}}}
\bibcite{louhaichi2001spatially}{{9}{2001}{{Louhaichi et~al.}}{{}}}
\bibcite{hamuda2016survey}{{10}{2016}{{Hamuda et~al.}}{{}}}
\bibcite{mathieu1998relationships}{{11}{1998}{{Mathieu et~al.}}{{}}}
\bibcite{meyer2008verification}{{12}{2008}{{Meyer and Neto}}{{}}}
\bibcite{henrich2012entwicklung}{{13}{2012}{{Henrich et~al.}}{{}}}
\bibcite{2020SciPy-NMeth}{{14}{2020}{{Virtanen et~al.}}{{}}}
\bibcite{nelder1965simplex}{{15}{1965}{{Nelder and Mead}}{{}}}
\bibcite{Peccia_2018}{{16}{2018}{{Peccia}}{{}}}
\bibcite{he2016deep}{{17}{2016}{{He et~al.}}{{}}}
\bibcite{chollet2015keras}{{18}{2015}{{Chollet et~al.}}{{}}}
\bibcite{tanaka_review_2024}{{19}{2024}{{Tanaka et~al.}}{{}}}
\bibcite{gano2024drone}{{20}{2024a}{{Gano et~al.}}{{}}}
\bibcite{gano_dronebased_2024}{{21}{2024b}{{Gano et~al.}}{{}}}
\bibcite{sharma2021development}{{22}{2021}{{Sharma et~al.}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}References}{17}{section.5}\protected@file@percent }
\bibcite{vacca2020web}{{23}{2020}{{Vacca et~al.}}{{}}}
\bibcite{noauthor_orfeo_nodate}{{24}{}{{}}{{}}}
\bibcite{grizonnet_orfeo_2017}{{25}{2017}{{Grizonnet et~al.}}{{}}}
\bibcite{dobesova2020evaluation}{{26}{2020}{{Dobesova}}{{}}}
\bibcite{noauthor_plantcv_2021}{{27}{2021}{{}}{{}}}
\bibcite{varghese2024yolov8}{{28}{2024}{{Varghese and Sambath}}{{}}}
\bibcite{matias_fieldimager_2020}{{29}{2020}{{Matias et~al.}}{{}}}
\bibcite{ChenZhang2020}{{30}{2020}{{Chen and Zhang}}{{}}}
\bibcite{itoh2024preps}{{31}{2024}{{Itoh et~al.}}{{}}}
\bibcite{wang2024ihup}{{32}{2024}{{Wang et~al.}}{{}}}
\bibcite{candiago2015evaluating}{{33}{2015}{{Candiago et~al.}}{{}}}
\bibcite{radovcaj2023state}{{34}{2023}{{Rado{\v {c}}aj et~al.}}{{}}}
\bibcite{velez2023beyond}{{35}{2023}{{V{\'e}lez et~al.}}{{}}}
\newlabel{LastPage}{{}{18}{}{page.18}{}}
\xdef\lastpage@lastpage{18}
\xdef\lastpage@lastpageHy{18}
\gdef \@abspage@last{18}
