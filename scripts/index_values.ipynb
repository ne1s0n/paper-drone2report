{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e0827d-e834-4fd4-aa5e-2de1edd3db22",
   "metadata": {},
   "source": [
    "## Explore how a vegetation index is calculated: effect of thresholding\n",
    "\n",
    "In this illustration, we take as example one RGB image of a single plot (`.png` thumbnail from `drone2report`), and one vegetation index, **GLI** (Green Leaf Index (more [here](https://www.indexdatabase.de/db/i-single.php?id=375)).\n",
    "\n",
    "We start by import libraries: we are using the `imageio` *Python* library for input/output of image data (png/tiff raster images in this illustration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959b018-4a3d-4e94-8c27-8289f60028c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91decc77-ae85-4aa1-836b-f34a663f824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../paper-drone2report/data/single_rgb_plot/single_rgb_plot.tif'\n",
    "pic = imageio.imread(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a53192-e2d8-4a8c-83a5-1132fd389fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a4cf3-06de-401a-87e1-2fc820c054fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the image : {}'.format(pic.shape))\n",
    "\n",
    "print('Total n. of pixels:', pic.shape[0]*pic.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928dd89-e8b6-4890-a024-bf8c0958f72c",
   "metadata": {},
   "source": [
    "The input image has the characteristics detailed above, e.g. 3 channels and size 707 x 612 (height, width): **total number of input pixels is 432,684**.\n",
    "\n",
    "## Calculating the GLI index\n",
    "\n",
    "### Using drone2report\n",
    "\n",
    "The GLI (Green Leaf Index) was calculated with the `drone2report` software, using [this configuration file: RGB_GLI.ini](https://github.com/ne1s0n/paper-drone2report/blob/main/support_material/RGB_GLI.ini).\n",
    "The calculations were based on $254\\,493$ pixels: \n",
    "\n",
    "- average GLI = 0.26837\n",
    "- median GLI = 0.25397\n",
    "- std dev GLI = 0.147\n",
    "- min, max GLU = $[-0.3684, 0.98Ã¬775]$\n",
    "\n",
    "**<div style=\"color:red\">Question: can GLI be negative?</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d98756-2cac-4b49-be8b-a13dbc96e992",
   "metadata": {},
   "source": [
    "### Step-by-step calculations\n",
    "\n",
    "We need to change the Python environemnt settings so to ignore warnings that are raised when division by zero is encountered: this is something that can easily happen when you work with high dimensional arrays (there may be a zero somewhere):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f2a3f-34d7-45bb-b860-ede7c82b4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is a setting to ignore warnings when attempting to divide by 0\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce691d-dd27-4afd-bd5b-e0fa75d894b2",
   "metadata": {},
   "source": [
    "Now, we calculate the GLI index manually:\n",
    "\n",
    "1. we first define the three channels\n",
    "2. we then separate the three channels from the `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973bfb8-1a91-4bdb-ae4d-9c2e9991b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['red','green','blue']\n",
    "channels.index('red') ## index of the red channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772384a-6784-494e-ac4c-77710f01c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "red   = pic[:,:,channels.index('red')]\n",
    "green = pic[:,:,channels.index('green')]\n",
    "blue  = pic[:,:,channels.index('blue')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5c7b6-754f-4a56-bd68-403ba13ecbbc",
   "metadata": {},
   "source": [
    "These are three 2D arrays of numbers (pixel intensities), corresponding to the three color channels: we see the zeros that correspond to the black pixels in the four corners around the crop plot (and this shows that we are bound to have divisions by zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49444712-9fd2-4c8b-bb3c-c53ec146f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d47bb-bd2e-4fce-9e6b-a2afd8cd2e68",
   "metadata": {},
   "source": [
    "We then take the equation to calculate the [GLI index](https://www.indexdatabase.de/db/i-single.php?id=375) and implement it using our arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd08fea-deac-4a14-be65-c7675f0398dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli = (2.0*green - red - blue) / (2.0*green + red + blue)\n",
    "gli[100:120, 220:280]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0ab2a-645d-4b9c-8608-36e86bbf1051",
   "metadata": {},
   "source": [
    "We see that, due to the presence of manay divisions by zero, `nan` are introduced in the numpy array (missing or undetermined data points): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a58b1-a195-4b4f-b410-07853d97d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a8d82-2484-4bbc-a955-575a135b25f1",
   "metadata": {},
   "source": [
    "Below, the **heatmap of the GLI values 2D array**: nan are displayed as white (missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f5649-7685-48a0-bc69-e0b46a36ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gli, cmap='summer', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52dc1e-718e-4c5e-984c-deb47c9a29b1",
   "metadata": {},
   "source": [
    "To get the average value of the GLI index for the whole plot (as is done by `drone2report`), we can take the average: the standard `np.mean()` wouldn't work, as there ara `nan`'s in the data; therefore we use a modified version of the function that removes `nan`'s before calculating the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712cc29-d896-4fca-b99b-3d401e194ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.nanmean(gli)\n",
    "print(\"Average GLI value calculated manually, where divisions by zero returned NaN's:\", round(avg,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013915ac-8ee9-4d0f-9a12-f079546b1b0e",
   "metadata": {},
   "source": [
    "We can force division to zero to return zero instead of `nan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30b67c-fbf5-4bf1-adbd-921527036f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (2.0*green - red - blue)\n",
    "y = (2.0*green + red + blue)\n",
    "\n",
    "gli = np.divide(x, y, out=np.zeros_like(x), where=y!=0)\n",
    "gli[100:120, 220:280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9804ed-283c-4389-aebe-e49fbd53beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c9b48-fdc7-46de-8663-f22133d5bc1a",
   "metadata": {},
   "source": [
    "In the **heatmap of the GLI values 2D array**, now the `nan` are replaced by 0's, i.e. max saturation of those pixels (depending on the chosen color map this will be displayed as the darkest possible color in that channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426c357-63a8-491c-aafa-5d4dfad80049",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gli, cmap='summer', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5792c37-5a48-4ec6-9427-c4fdbacbcaf5",
   "metadata": {},
   "source": [
    "Now there are no `nan`'s, therefore we can use the usual function `np.mean()`: however, 0's are numbers!! \n",
    "They add nothing to the numerator, but add counts to the denominator, and the results is consequently biased downward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6d338-e040-4a55-a71a-43a01ee7c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.mean(gli)\n",
    "print(\"Average GLI value calculated manually, where divisions by zero returned 0's:\", round(avg,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347cd373-0958-4ae9-8d24-984584eca08a",
   "metadata": {},
   "source": [
    "We see that the corners around the crop plot introduce some operational and interpretation problems, either when they are `nan`'s or when they're forced to be 0's.\n",
    "\n",
    "A better solution is needed: this is **masking**, i.e. unnecessary pixels like those in the corners are \"masked\", hence not used in the calculations (no problems with `nan`s or 0's).\n",
    "\n",
    "Before moving on to masking, we wrap all the code needed to calculate the GLI index into a **function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03409900-9167-4733-a7c7-8a02bdaa215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLI(img, channels):\n",
    "\t\"\"\"Green leaf index, uses red, green, blue\"\"\"\n",
    "\ttry:\n",
    "\t\tred   = img[:,:,channels.index('red')]\n",
    "\t\tgreen = img[:,:,channels.index('green')]\n",
    "\t\tblue  = img[:,:,channels.index('blue')]\n",
    "\texcept ValueError:\n",
    "\t\t#if this clause is activated it means that the requested channel(s) are not available\n",
    "\t\treturn np.nan\n",
    "\t#if we get here the index can be applied to the current image\n",
    "\treturn(\n",
    "\t\t(2.0*green - red - blue) / \n",
    "\t\t(2.0*green + red + blue)\n",
    "\t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993e155-626f-41e8-bd2a-e957f8b47ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli = GLI(pic, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cfa05-4b12-4d0a-9e46-f6103e485d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli[100:120, 220:280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4076cb9-65bf-4145-a984-c8b3d54bb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(gli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70060cc5-9220-4918-8d26-31ffb77d8d42",
   "metadata": {},
   "source": [
    "## Masked arrays\n",
    "\n",
    "### Masking unnecessary values in the index matrix\n",
    "\n",
    "We first try masking unnecessary values of the index (the triangular margins outside of the ROI).\n",
    "We do this by **masking index values calculated on out-of-shape pixels**.\n",
    "\n",
    "This is a quick-n-dirty initial attempt.\n",
    "A better way would be to mask directly the grey pixels in the input RGB image data (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e9096-7a37-4f9e-a871-c65557b83275",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00750cf3-fe0b-43f0-ab18-53994f2d36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0 = np.isnan(gli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f18164-59ef-44ed-b997-2a99ee8a6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06c41d-dc87-4183-bc05-f617ba28138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gli = ma.masked_array(gli, mask_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fde80-0e18-4992-82e8-91fc3f87ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d6bdb-5e06-4610-93e9-a57bafcb788d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "masked_pixels = np.ma.sum(mask_0)\n",
    "print(masked_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86786a86-f963-4d74-80b8-e174595feb93",
   "metadata": {},
   "source": [
    "The total n. of masked pixels is $185\\,975$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0bcaf5-ad73-44ed-84c3-c2c8d9cc0c3b",
   "metadata": {},
   "source": [
    "The total n. of pixels is given by the product of the width and height of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f36c48-cc9d-467d-b750-473eb552c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0.shape[0] * mask_0.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456acecb-9dfb-4b8e-8830-18f26c8cce85",
   "metadata": {},
   "source": [
    "We can now calculate the number of pixels used for the calculation of the average index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c826cc7-9d9c-4a7c-9a0b-d4c557153f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask_0.shape[0] * mask_0.shape[1]) - np.ma.sum(mask_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a005271-dbe1-42bb-aaed-c8eb35ea678a",
   "metadata": {},
   "source": [
    "$254\\,486$ pixels were used to claculate the average GLI index from the matrix of GLI values per pixel.\n",
    "\n",
    "**<div style=\"color:red\">Check: this is slightly different from the number of used pixels reported by `drone2report`: $254\\,493$ pixels</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd5ff2-e952-4c4c-90b3-c3cb3ede779c",
   "metadata": {},
   "source": [
    "#### Average GLI value on single plot calculated after masking\n",
    "\n",
    "Masking was based on GLI values (0s were masked):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5563b-f3a9-46e3-9b51-1c0d550eb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.ma.mean(masked_gli),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43b565-14a9-46e9-8831-0d136164d113",
   "metadata": {},
   "source": [
    "### Masking directly the input data\n",
    "\n",
    "An even better approach, at least in principle, is to mask the unnecessary pixels directly in the image data, before calculating the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91288465-218e-49eb-93e8-c42ceef31f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = imageio.imread(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e442e28-4c62-4b07-804b-7df30dfd996b",
   "metadata": {},
   "source": [
    "Sanity check: let's view the current image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d5cfd-1d5d-4d1c-895d-1ffeee8b728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b5c78-7eee-4557-aaa1-533301d7609a",
   "metadata": {},
   "source": [
    "**Important**: we have three channels (RGB), and the corners in the `tif` image are black, hence the corresponding pixels are zero-valued in all three channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed911060-28ce-4f98-b433-a27a425f8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5bc3bc-5c82-43ad-a537-cd71f32fdaa8",
   "metadata": {},
   "source": [
    "For the masking, we need to impose the condition across layers: we use `np.all()` on the second axis, as we want the condition to be true if the same pixel position is zero in all three channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa3fa8-b953-4b60-b6a1-03eaa9d3de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0 = np.all(pic == 0, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479d60c-2c79-40ff-9ded-a69b681b7b07",
   "metadata": {},
   "source": [
    "We check the result visually with a heatmap: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becb777-d5e0-4cc7-b616-47d7bb148172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_0, cmap='grey', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a876e-b44f-484b-a2a6-7d253b763733",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0[100:160,160:220]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad113d-9f41-4de4-8389-e962dd5b2302",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The n. of masked pixels is slightly different compared to the masking of the GLI index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca2e35-3254-4382-afe7-e1bcf5c17f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.ma.sum(mask_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738e86b-fa72-436c-8bba-3dbc36fb4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7063f-0c32-4ef1-9697-e100e876af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tot = np.dstack((mask_0,mask_0,mask_0))\n",
    "mask_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e820e-bfcb-493d-afa7-dc1272d8763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tot[100:160,160:220,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de6879-0146-445c-948d-5de200683822",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic[120:160, 160:220, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ad44e-ba4f-48f6-ab5e-d4105cbac225",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pic = ma.masked_array(pic, mask_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95226b49-56e0-4e8a-8458-00d37838e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pic[120:160, 180:220, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39f460-b07c-4468-984f-f7058465439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "red   = masked_pic[:,:,channels.index('red')]\n",
    "green = masked_pic[:,:,channels.index('green')]\n",
    "blue  = masked_pic[:,:,channels.index('blue')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b0a1f-a0dd-45a3-aac8-9e0f91fb812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "red[120:160, 180:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275e52b-4346-4b30-9640-6f7376f453a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (2.0*green - red - blue) / (2.0*green + red + blue)\n",
    "temp[120:160, 180:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376287d-d921-4794-a4cc-6ff319cd93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.ma.mean(temp),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef163f00-c551-4e63-bd7c-0f48c612c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7e5aa-08f5-451d-8751-81fafcbb2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f2f0e-78d0-4ff4-814f-f8ec13a6a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = temp[temp.mask == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b860f84-9786-4915-9a8f-00e39aa9cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d80e6e-94db-41f2-8848-6b861325d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2facc8d-df68-4ef6-8e5f-580e194a80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x, bins=60)\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
